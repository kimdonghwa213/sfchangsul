"""
AWS ê¸°ìƒ ë°ì´í„° ê¸°ë°˜ ML ì˜ˆì¸¡ ëª¨ë¸
- LSTM: ì‹œê³„ì—´ ë”¥ëŸ¬ë‹ ëª¨ë¸
- Prophet: Facebook ì‹œê³„ì—´ ì˜ˆì¸¡
- Random Forest: ì•™ìƒë¸” ëª¨ë¸
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
import pickle
import warnings
warnings.filterwarnings('ignore')

# ML ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ë”¥ëŸ¬ë‹
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential, load_model
from keras.layers import LSTM, Dense, Dropout
from keras.callbacks import EarlyStopping, ModelCheckpoint

# Prophet (Facebook ì‹œê³„ì—´ ì˜ˆì¸¡)
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    print("Prophet ì„¤ì¹˜ ê¶Œì¥: pip install prophet")


class AWSDataCollector:
    """AWS ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, site_id=85, dev_id=1):
        self.site_id = site_id
        self.dev_id = dev_id
        self.base_url = "http://203.239.47.148:8080/dspnet.aspx"
    
    def fetch_single_day(self, date):
        """í•˜ë£¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        params = {
            'Site': self.site_id,
            'Dev': self.dev_id,
            'Year': date.year,
            'Mon': date.month,
            'Day': date.day
        }
        
        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            lines = response.text.strip().split('\n')
            data = []
            
            for line in lines:
                parts = line.split(',')
                if len(parts) >= 17:
                    try:
                        data.append({
                            'datetime': datetime.strptime(parts[0].strip(), '%Y-%m-%d %H:%M:%S'),
                            'temperature': float(parts[1].strip()),
                            'humidity': float(parts[2].strip()),
                            'solar_radiation': float(parts[6].strip()),
                            'wind_direction': float(parts[7].strip()),
                            'wind_speed': float(parts[13].strip()),
                            'rainfall': float(parts[14].strip()),
                            'max_wind_gust': float(parts[15].strip()),
                            'battery_voltage': float(parts[16].strip())
                        })
                    except (ValueError, IndexError):
                        continue
            
            return pd.DataFrame(data)
        
        except Exception as e:
            print(f"ë‚ ì§œ {date} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def fetch_date_range(self, start_date, end_date):
        """ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘"""
        all_data = []
        current_date = start_date
        
        print(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {start_date.date()} ~ {end_date.date()}")
        
        while current_date <= end_date:
            print(f"  ìˆ˜ì§‘ ì¤‘: {current_date.date()}", end='\r')
            df = self.fetch_single_day(current_date)
            
            if df is not None and len(df) > 0:
                all_data.append(df)
            
            current_date += timedelta(days=1)
        
        if all_data:
            result = pd.concat(all_data, ignore_index=True)
            result = result.sort_values('datetime').reset_index(drop=True)
            print(f"\nâœ… ì´ {len(result)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            return result
        else:
            print("\nâŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return None


class WeatherFeatureEngineering:
    """ê¸°ìƒ ë°ì´í„° íŠ¹ì„± ê³µí•™"""
    
    @staticmethod
    def add_time_features(df):
        """ì‹œê°„ ê´€ë ¨ íŠ¹ì„± ì¶”ê°€"""
        df = df.copy()
        df['hour'] = df['datetime'].dt.hour
        df['day'] = df['datetime'].dt.day
        df['month'] = df['datetime'].dt.month
        df['day_of_week'] = df['datetime'].dt.dayofweek
        df['day_of_year'] = df['datetime'].dt.dayofyear
        
        # ì£¼ê¸°ì  íŠ¹ì„± (ì‚¬ì¸/ì½”ì‚¬ì¸ ì¸ì½”ë”©)
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        
        return df
    
    @staticmethod
    def add_lag_features(df, columns, lags=[1, 3, 6, 12, 24]):
        """ê³¼ê±° ê°’ íŠ¹ì„± ì¶”ê°€"""
        df = df.copy()
        
        for col in columns:
            for lag in lags:
                df[f'{col}_lag_{lag}'] = df[col].shift(lag)
        
        return df
    
    @staticmethod
    def add_rolling_features(df, columns, windows=[3, 6, 12, 24]):
        """ì´ë™ í‰ê·  íŠ¹ì„± ì¶”ê°€"""
        df = df.copy()
        
        for col in columns:
            for window in windows:
                df[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()
                df[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()
        
        return df
    
    @staticmethod
    def create_features(df):
        """ì „ì²´ íŠ¹ì„± ìƒì„±"""
        df = WeatherFeatureEngineering.add_time_features(df)
        
        # ì£¼ìš” ë³€ìˆ˜ì— ëŒ€í•œ lag ë° rolling íŠ¹ì„±
        main_cols = ['temperature', 'humidity', 'wind_speed', 'solar_radiation']
        df = WeatherFeatureEngineering.add_lag_features(df, main_cols)
        df = WeatherFeatureEngineering.add_rolling_features(df, main_cols)
        
        # ê²°ì¸¡ì¹˜ ì œê±° (lag, rollingìœ¼ë¡œ ì¸í•œ)
        df = df.dropna().reset_index(drop=True)
        
        return df


class LSTMWeatherModel:
    """LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, sequence_length=24, n_features=None):
        self.sequence_length = sequence_length
        self.n_features = n_features
        self.model = None
        self.scaler = MinMaxScaler()
        self.feature_columns = None
        
    def prepare_sequences(self, data, target_col):
        """ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
        X, y = [], []
        
        for i in range(len(data) - self.sequence_length):
            X.append(data[i:i + self.sequence_length])
            y.append(data[i + self.sequence_length][target_col])
        
        return np.array(X), np.array(y)
    
    def build_model(self):
        """LSTM ëª¨ë¸ êµ¬ì¶•"""
        model = Sequential([
            LSTM(128, activation='relu', return_sequences=True, 
                 input_shape=(self.sequence_length, self.n_features)),
            Dropout(0.2),
            LSTM(64, activation='relu', return_sequences=True),
            Dropout(0.2),
            LSTM(32, activation='relu'),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1)
        ])
        
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model
    
    def train(self, df, target_col='temperature', epochs=100, batch_size=32):
        """ëª¨ë¸ í•™ìŠµ"""
        # íŠ¹ì„± ì„ íƒ
        self.feature_columns = [col for col in df.columns 
                               if col not in ['datetime', 'battery_voltage']]
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        scaled_data = self.scaler.fit_transform(df[self.feature_columns])
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì¸ë±ìŠ¤
        target_idx = self.feature_columns.index(target_col)
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        X, y = self.prepare_sequences(scaled_data, target_idx)
        
        # Train/Validation ë¶„í• 
        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        
        print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}, ê²€ì¦ ë°ì´í„°: {X_val.shape}")
        
        # ëª¨ë¸ êµ¬ì¶•
        self.n_features = X.shape[2]
        self.model = self.build_model()
        
        # ì½œë°± ì„¤ì •
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
            ModelCheckpoint('best_lstm_model.h5', save_best_only=True, monitor='val_loss')
        ]
        
        # í•™ìŠµ
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        # í‰ê°€
        train_pred = self.model.predict(X_train)
        val_pred = self.model.predict(X_val)
        
        train_mae = mean_absolute_error(y_train, train_pred)
        val_mae = mean_absolute_error(y_val, val_pred)
        
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"Train MAE: {train_mae:.4f}")
        print(f"Validation MAE: {val_mae:.4f}")
        
        return history
    
    def predict_future(self, df, hours=24):
        """ë¯¸ë˜ ì˜ˆì¸¡"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ìµœê·¼ ë°ì´í„°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±
        recent_data = df[self.feature_columns].tail(self.sequence_length).values
        scaled_recent = self.scaler.transform(recent_data)
        
        predictions = []
        current_sequence = scaled_recent.copy()
        
        for _ in range(hours):
            # ì˜ˆì¸¡
            X_pred = current_sequence.reshape(1, self.sequence_length, self.n_features)
            pred_scaled = self.model.predict(X_pred, verbose=0)[0, 0]
            
            # ë‹¤ìŒ ì‹œí€€ìŠ¤ ìƒì„± (ì˜ˆì¸¡ê°’ì„ í¬í•¨)
            next_step = current_sequence[-1].copy()
            next_step[0] = pred_scaled  # ì˜¨ë„ ìœ„ì¹˜ì— ì˜ˆì¸¡ê°’ ì—…ë°ì´íŠ¸
            
            current_sequence = np.vstack([current_sequence[1:], next_step])
            predictions.append(pred_scaled)
        
        # ì—­ìŠ¤ì¼€ì¼ë§
        predictions = np.array(predictions).reshape(-1, 1)
        
        # ì „ì²´ íŠ¹ì„±ì„ ìœ„í•œ ë”ë¯¸ ë°ì´í„° ìƒì„±
        dummy = np.zeros((len(predictions), len(self.feature_columns)))
        dummy[:, 0] = predictions.flatten()
        predictions_unscaled = self.scaler.inverse_transform(dummy)[:, 0]
        
        return predictions_unscaled
    
    def save(self, filepath='lstm_model.h5'):
        """ëª¨ë¸ ì €ì¥"""
        self.model.save(filepath)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ì™€ ì„¤ì • ì €ì¥
        config = {
            'scaler': self.scaler,
            'feature_columns': self.feature_columns,
            'sequence_length': self.sequence_length,
            'n_features': self.n_features
        }
        with open(filepath.replace('.h5', '_config.pkl'), 'wb') as f:
            pickle.dump(config, f)
    
    def load(self, filepath='lstm_model.h5'):
        """ëª¨ë¸ ë¡œë“œ"""
        self.model = load_model(filepath)
        
        with open(filepath.replace('.h5', '_config.pkl'), 'rb') as f:
            config = pickle.load(f)
        
        self.scaler = config['scaler']
        self.feature_columns = config['feature_columns']
        self.sequence_length = config['sequence_length']
        self.n_features = config['n_features']


class RandomForestWeatherModel:
    """Random Forest ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self):
        self.models = {}
        self.scaler = MinMaxScaler()
        self.feature_columns = None
    
    def train(self, df, targets=['temperature', 'humidity', 'wind_speed']):
        """ë‹¤ì¤‘ íƒ€ê²Ÿ í•™ìŠµ"""
        # íŠ¹ì„± ì„ íƒ
        self.feature_columns = [col for col in df.columns 
                               if col not in ['datetime', 'battery_voltage'] + targets]
        
        X = df[self.feature_columns].values
        X = self.scaler.fit_transform(X)
        
        # Train/Test ë¶„í• 
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        
        print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape[0]}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}")
        
        # ê° íƒ€ê²Ÿë³„ ëª¨ë¸ í•™ìŠµ
        for target in targets:
            print(f"\nğŸ“Š {target} ëª¨ë¸ í•™ìŠµ ì¤‘...")
            
            y = df[target].values
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            # Random Forest ëª¨ë¸
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=20,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            )
            
            model.fit(X_train, y_train)
            
            # í‰ê°€
            train_pred = model.predict(X_train)
            test_pred = model.predict(X_test)
            
            train_mae = mean_absolute_error(y_train, train_pred)
            test_mae = mean_absolute_error(y_test, test_pred)
            test_r2 = r2_score(y_test, test_pred)
            
            print(f"  Train MAE: {train_mae:.4f}")
            print(f"  Test MAE: {test_mae:.4f}")
            print(f"  Test RÂ²: {test_r2:.4f}")
            
            # ì¤‘ìš” íŠ¹ì„± ì¶œë ¥
            feature_importance = pd.DataFrame({
                'feature': self.feature_columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print(f"  Top 5 ì¤‘ìš” íŠ¹ì„±:")
            for idx, row in feature_importance.head(5).iterrows():
                print(f"    {row['feature']}: {row['importance']:.4f}")
            
            self.models[target] = model
        
        print("\nâœ… ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    def predict(self, df, hours=24):
        """ë¯¸ë˜ ì˜ˆì¸¡"""
        predictions = {target: [] for target in self.models.keys()}
        
        # ìµœê·¼ ë°ì´í„°ë¡œ ì‹œì‘
        current_df = df.copy()
        
        for hour in range(hours):
            # íŠ¹ì„± ì¶”ì¶œ
            X = current_df[self.feature_columns].tail(1).values
            X_scaled = self.scaler.transform(X)
            
            # ê° íƒ€ê²Ÿ ì˜ˆì¸¡
            for target, model in self.models.items():
                pred = model.predict(X_scaled)[0]
                predictions[target].append(pred)
            
            # ë‹¤ìŒ ì‹œê°„ ë°ì´í„° ìƒì„± (ì˜ˆì¸¡ê°’ ì‚¬ìš©)
            next_row = current_df.iloc[-1].copy()
            next_row['datetime'] = next_row['datetime'] + timedelta(hours=1)
            
            for target in self.models.keys():
                next_row[target] = predictions[target][-1]
            
            # íŠ¹ì„± ì¬ê³„ì‚° (ì‹œê°„ ê´€ë ¨)
            next_row['hour'] = next_row['datetime'].hour
            next_row['day'] = next_row['datetime'].day
            next_row['month'] = next_row['datetime'].month
            
            current_df = pd.concat([current_df, next_row.to_frame().T], ignore_index=True)
        
        return predictions
    
    def save(self, filepath='rf_models.pkl'):
        """ëª¨ë¸ ì €ì¥"""
        config = {
            'models': self.models,
            'scaler': self.scaler,
            'feature_columns': self.feature_columns
        }
        with open(filepath, 'wb') as f:
            pickle.dump(config, f)
    
    def load(self, filepath='rf_models.pkl'):
        """ëª¨ë¸ ë¡œë“œ"""
        with open(filepath, 'rb') as f:
            config = pickle.load(f)
        
        self.models = config['models']
        self.scaler = config['scaler']
        self.feature_columns = config['feature_columns']


class ProphetWeatherModel:
    """Prophet ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self):
        if not PROPHET_AVAILABLE:
            raise ImportError("Prophetì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install prophet")
        
        self.models = {}
    
    def train(self, df, targets=['temperature', 'humidity']):
        """Prophet ëª¨ë¸ í•™ìŠµ"""
        for target in targets:
            print(f"\nğŸ“Š {target} Prophet ëª¨ë¸ í•™ìŠµ ì¤‘...")
            
            # Prophet í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            prophet_df = pd.DataFrame({
                'ds': df['datetime'],
                'y': df[target]
            })
            
            # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
            model = Prophet(
                yearly_seasonality=True,
                weekly_seasonality=True,
                daily_seasonality=True,
                changepoint_prior_scale=0.05
            )
            
            model.fit(prophet_df)
            self.models[target] = model
            
            print(f"  âœ… {target} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    def predict(self, hours=24):
        """ë¯¸ë˜ ì˜ˆì¸¡"""
        predictions = {}
        
        for target, model in self.models.items():
            # ë¯¸ë˜ ë‚ ì§œ ìƒì„±
            future = model.make_future_dataframe(periods=hours, freq='H')
            
            # ì˜ˆì¸¡
            forecast = model.predict(future)
            
            # ë§ˆì§€ë§‰ 24ì‹œê°„ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
            predictions[target] = forecast['yhat'].tail(hours).values
        
        return predictions
    
    def save(self, filepath='prophet_models.pkl'):
        """ëª¨ë¸ ì €ì¥"""
        with open(filepath, 'wb') as f:
            pickle.dump(self.models, f)
    
    def load(self, filepath='prophet_models.pkl'):
        """ëª¨ë¸ ë¡œë“œ"""
        with open(filepath, 'rb') as f:
            self.models = pickle.load(f)


# ==================== ì‚¬ìš© ì˜ˆì œ ====================

if __name__ == "__main__":
    print("ğŸŒ± AWS ê¸°ìƒ ë°ì´í„° ML ì˜ˆì¸¡ ì‹œìŠ¤í…œ\n")
    
    # 1. ë°ì´í„° ìˆ˜ì§‘
    print("=" * 50)
    print("1ï¸âƒ£ ë°ì´í„° ìˆ˜ì§‘")
    print("=" * 50)
    
    collector = AWSDataCollector(site_id=85, dev_id=1)
    
    # ìµœê·¼ 3ê°œì›” ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì œë¡œëŠ” ë” ë§ì€ ë°ì´í„° ê¶Œì¥)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=90)
    
    df = collector.fetch_date_range(start_date, end_date)
    
    if df is None or len(df) == 0:
        print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. ìƒ˜í”Œ ë°ì´í„°ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        dates = pd.date_range(start=start_date, end=end_date, freq='10T')
        df = pd.DataFrame({
            'datetime': dates,
            'temperature': 20 + 10 * np.sin(np.arange(len(dates)) * 2 * np.pi / 144) + np.random.randn(len(dates)),
            'humidity': 60 + 20 * np.cos(np.arange(len(dates)) * 2 * np.pi / 144) + np.random.randn(len(dates)) * 5,
            'wind_speed': 2 + np.random.randn(len(dates)) * 0.5,
            'solar_radiation': np.maximum(0, 500 * np.sin(np.arange(len(dates)) * 2 * np.pi / 144)),
            'wind_direction': np.random.uniform(0, 360, len(dates)),
            'rainfall': 0,
            'max_wind_gust': 3 + np.random.randn(len(dates)) * 0.5,
            'battery_voltage': 12.5 + np.random.randn(len(dates)) * 0.1
        })
    
    # 2. íŠ¹ì„± ê³µí•™
    print("\n" + "=" * 50)
    print("2ï¸âƒ£ íŠ¹ì„± ê³µí•™")
    print("=" * 50)
    
    df_features = WeatherFeatureEngineering.create_features(df)
    print(f"íŠ¹ì„± ê°œìˆ˜: {len(df_features.columns)}")
    print(f"ë°ì´í„° ê°œìˆ˜: {len(df_features)}")
    
    # 3. LSTM ëª¨ë¸ í•™ìŠµ
    print("\n" + "=" * 50)
    print("3ï¸âƒ£ LSTM ëª¨ë¸ í•™ìŠµ")
    print("=" * 50)
    
    lstm_model = LSTMWeatherModel(sequence_length=24)
    lstm_model.train(df_features, target_col='temperature', epochs=50)
    lstm_model.save('lstm_weather_model.h5')
    
    # ì˜ˆì¸¡
    lstm_predictions = lstm_model.predict_future(df_features, hours=24)
    print(f"\nLSTM 24ì‹œê°„ ì˜¨ë„ ì˜ˆì¸¡: {lstm_predictions[:5]} ...")
    
    # 4. Random Forest ëª¨ë¸ í•™ìŠµ
    print("\n" + "=" * 50)
    print("4ï¸âƒ£ Random Forest ëª¨ë¸ í•™ìŠµ")
    print("=" * 50)
    
    rf_model = RandomForestWeatherModel()
    rf_model.train(df_features, targets=['temperature', 'humidity', 'wind_speed'])
    rf_model.save('rf_weather_models.pkl')
    
    # ì˜ˆì¸¡
    rf_predictions = rf_model.predict(df_features, hours=24)
    print(f"\nRandom Forest 24ì‹œê°„ ì˜¨ë„ ì˜ˆì¸¡: {rf_predictions['temperature'][:5]} ...")
    
    # 5. Prophet ëª¨ë¸ í•™ìŠµ (ì„ íƒì )
    if PROPHET_AVAILABLE:
        print("\n" + "=" * 50)
        print("5ï¸âƒ£ Prophet ëª¨ë¸ í•™ìŠµ")
        print("=" * 50)
        
        prophet_model = ProphetWeatherModel()
        prophet_model.train(df, targets=['temperature', 'humidity'])
        prophet_model.save('prophet_weather_models.pkl')
        
        prophet_predictions = prophet_model.predict(hours=24)
        print(f"\nProphet 24ì‹œê°„ ì˜¨ë„ ì˜ˆì¸¡: {prophet_predictions['temperature'][:5]} ...")
    
    print("\n" + "=" * 50)
    print("âœ… ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")
    print("=" * 50)